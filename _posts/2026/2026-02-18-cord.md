---
layout: post
title: "Cord: Coordinating Trees of AI Agents"
tags: coding
---

AI agents are getting good at doing one thing at a time. Give Claude or GPT a focused task — write this function, research this topic, analyze this data — and it performs well. But real work isn't one task. It's a tree of tasks with dependencies, parallelism, and context that needs to flow between them.

The industry knows this. Everyone is building multi-agent frameworks. And they're all solving the wrong problem.

## The Orchestration Landscape

**LangGraph** (LangChain) models agent coordination as a state machine. You define nodes and edges in Python. The developer decides upfront how agents hand off work — which agent runs when, what state gets passed where. It's powerful for fixed workflows, but the graph is static. If an agent realizes mid-task that the work should be split differently, there's no mechanism for that. The developer has to anticipate every decomposition pattern in advance.

**CrewAI** takes a role-based approach. You define agents with personas — "researcher," "analyst," "writer" — and assign them tasks. It's intuitive, but the roles are decided by the developer, not discovered by the agents. A crew of three can't decide it actually needs five people, or that the "researcher" role should be split into two parallel tracks.

**AutoGen** (Microsoft) puts agents in a group chat. They coordinate by talking to each other. This is flexible — any agent can say anything — but there's no structure. No dependency tracking, no authority scoping, no typed results. Coordination emerges from conversation, which means it's unpredictable and hard to inspect.

**OpenAI Swarm** is the most minimal — lightweight handoffs between agents using function calls. Agent A decides it's time for Agent B and transfers control. Simple, but it's linear. No parallelism, no tree structure, no way for an agent to spawn three subtasks and wait for all of them.

**Claude's tool-use loops** — Anthropic's own pattern — put a single agent in a loop with tools. The agent calls tools, gets results, calls more tools. This handles sequential complexity well but runs into context window limits on large tasks and can't parallelize. One agent, one thread, one context.

## The Common Thread

Every framework requires the developer to predefine the coordination structure. *You* decide the workflow graph, the agent roles, the handoff pattern. The agents execute within boundaries you set.

This made sense when agents were unreliable. You'd never let GPT-3 decide how to decompose a project. But current models are good at planning. They break problems into subproblems naturally. They understand dependencies. They know when a task is too big for one pass.

So why are we still hardcoding the decomposition?

## What If the Agent Built the Tree?

I built [Cord](https://github.com/kimjune01/cord). You give it a goal:

```
cord run "Build a competitive landscape report for fintech"
```

One agent launches. It reads the goal, decides it's too complex for a single pass, and calls `spawn()` to create subtasks:

```
● #1 [active] GOAL Build a competitive landscape report for fintech
  ● #2 [active] SPAWN Identify top fintech competitors
  ● #3 [active] SPAWN Research fintech industry trends
  ○ #4 [pending] FORK Deep competitive analysis
    blocked-by: #2, #3
  ○ #5 [pending] SPAWN Write executive report
    blocked-by: #4
```

No workflow was hardcoded. The agent decided on this structure at runtime. It chose to parallelize #2 and #3, made #4 a `fork` (so it inherits the research context), and sequenced #5 after the analysis.

The engine watches the SQLite database. When #2 and #3 both complete, it launches #4 with their results injected. When #4 finishes, #5 starts. When everything is done, #1 relaunches to synthesize the final report.

## Spawn vs Fork

The one idea in Cord that I think is new: the distinction between `spawn` and `fork` as a context-flow primitive.

A **spawned** agent gets a clean slate. Just its prompt and the results of nodes it explicitly depends on. Like hiring a contractor — here's the spec, go do it. Cheap to restart, easy to reason about.

A **forked** agent gets all completed sibling results injected into its context. Like briefing a team member — they know everything the team has learned so far. More expensive (bigger context), but necessary for analysis that builds on prior work.

This isn't about concurrency. Both can run in parallel or sequentially. It's about *what the child knows*. In the fintech example, the root agent chose `spawn` for the independent research tasks and `fork` for the analysis that needs both results. It made this choice on its own — the model understands the distinction intuitively.

## How It Works

Each agent is a Claude Code CLI process with MCP tools backed by a shared SQLite database:

- `spawn(goal, prompt, blocked_by)` — create a child task
- `fork(goal, prompt, blocked_by)` — create a context-inheriting child
- `complete(result)` — mark yourself done
- `read_tree()` — see the full coordination tree

The agents don't know they're in a coordination tree. They see tools and use them as needed. The protocol — dependency resolution, authority scoping, result injection — is enforced by the MCP server, not by the agents.

The engine polls the database every 2 seconds: find ready nodes (pending + deps met), launch agents, poll for completions, render the TUI. When all children of a node complete, the parent relaunches with a synthesis prompt.

~500 lines of Python. SQLite + MCP. That's it.

## What I Observed

I ran 15 behavioral tests before building the runtime. Some findings:

**Agents decompose well.** Given `spawn()` and a complex goal, Claude breaks work into 3-6 subtasks with correct dependency ordering. No special prompting needed.

**Fork vs spawn is intuitive.** Claude chose `fork` for analysis tasks needing accumulated context and `spawn` for independent work. It described the distinction as "contractor vs team member" — the exact mental model from the spec, without being told.

**Authority works through failure.** When an agent tried to stop a sibling (unauthorized), it got rejected, then escalated via `ask parent` — the correct protocol behavior. The runtime is the guardrail, not the agent's judgment.

**Error recovery is aggressive.** When told to modify an active node (invalid), an agent tried pause+modify, failed, then stop+respawn. It found a workaround without being told the pattern. Creative, but it means the authority model must be strict — agents will find loopholes.

## What This Is Not

This implementation uses Claude Code CLI and SQLite. But the protocol — five primitives, dependency resolution, authority scoping, two-phase lifecycle — is independent of all of that.

You could implement Cord over Postgres for multi-machine coordination. Over the Claude API directly, skipping the CLI overhead. With multiple LLM providers — GPT for cheap tasks, Claude for complex ones. With human workers for some nodes.

The protocol is the contribution. This repo is a proof of concept.

## Try It

```bash
git clone https://github.com/kimjune01/cord.git
cd cord
uv sync
cord run "your goal here" --budget 2.0
```

Requires [Claude Code CLI](https://docs.anthropic.com/en/docs/claude-code) and a subscription that includes it.

[GitHub](https://github.com/kimjune01/cord) &#124; [RFC](https://github.com/kimjune01/cord/blob/master/RFC.md)
